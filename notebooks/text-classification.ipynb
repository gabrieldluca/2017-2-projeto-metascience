{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/vitorlima/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "from random import shuffle\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from nltk.classify import ClassifierI\n",
    "\n",
    "nltk.download('stopwords')\n",
    "random.seed(10)\n",
    "\n",
    "STOPWORDS = set(nltk.corpus.stopwords.words('english'))\n",
    "REGEX = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "STEMMER = SnowballStemmer('english')\n",
    "LEMMATIZER = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification (Naive Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>metascore</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_date</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>release_date</th>\n",
       "      <th>user_acclaim</th>\n",
       "      <th>user_score</th>\n",
       "      <th>...</th>\n",
       "      <th>Romance</th>\n",
       "      <th>SciFi</th>\n",
       "      <th>Short</th>\n",
       "      <th>Sport</th>\n",
       "      <th>TalkShow</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "      <th>unknown</th>\n",
       "      <th>release_decade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Notes on Blindness</td>\n",
       "      <td>Stephen Holden</td>\n",
       "      <td>75.0</td>\n",
       "      <td>90</td>\n",
       "      <td>The tone of the narration is so wrenchingly ho...</td>\n",
       "      <td>2016-11-15</td>\n",
       "      <td>pos</td>\n",
       "      <td>2016-11-16</td>\n",
       "      <td>No score yet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Devils on the Doorstep</td>\n",
       "      <td>Stephen Holden</td>\n",
       "      <td>70.0</td>\n",
       "      <td>80</td>\n",
       "      <td>In its dry and forceful way, it delivers the s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pos</td>\n",
       "      <td>2002-12-18</td>\n",
       "      <td>Universal acclaim</td>\n",
       "      <td>83.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Upside of Anger</td>\n",
       "      <td>Dana Stevens</td>\n",
       "      <td>63.0</td>\n",
       "      <td>60</td>\n",
       "      <td>A seriously flawed movie wrapped around two ne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mixed</td>\n",
       "      <td>2005-03-11</td>\n",
       "      <td>Generally favorable reviews</td>\n",
       "      <td>80.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Monster</td>\n",
       "      <td>Stephen Holden</td>\n",
       "      <td>74.0</td>\n",
       "      <td>70</td>\n",
       "      <td>The movie's biggest disappointment is the vagu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pos</td>\n",
       "      <td>2003-12-24</td>\n",
       "      <td>Generally favorable reviews</td>\n",
       "      <td>67.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rock in the Red Zone</td>\n",
       "      <td>Ken Jaworowski</td>\n",
       "      <td>54.0</td>\n",
       "      <td>50</td>\n",
       "      <td>Rock in the Red Zone has its best moments when...</td>\n",
       "      <td>2015-11-12</td>\n",
       "      <td>mixed</td>\n",
       "      <td>2015-11-12</td>\n",
       "      <td>No score yet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    movie        reviewer  metascore  review_score  \\\n",
       "0      Notes on Blindness  Stephen Holden       75.0            90   \n",
       "1  Devils on the Doorstep  Stephen Holden       70.0            80   \n",
       "2     The Upside of Anger    Dana Stevens       63.0            60   \n",
       "3                 Monster  Stephen Holden       74.0            70   \n",
       "4    Rock in the Red Zone  Ken Jaworowski       54.0            50   \n",
       "\n",
       "                                         review_text review_date sentiment  \\\n",
       "0  The tone of the narration is so wrenchingly ho...  2016-11-15       pos   \n",
       "1  In its dry and forceful way, it delivers the s...         NaN       pos   \n",
       "2  A seriously flawed movie wrapped around two ne...         NaN     mixed   \n",
       "3  The movie's biggest disappointment is the vagu...         NaN       pos   \n",
       "4  Rock in the Red Zone has its best moments when...  2015-11-12     mixed   \n",
       "\n",
       "  release_date                 user_acclaim  user_score       ...        \\\n",
       "0   2016-11-16                 No score yet         NaN       ...         \n",
       "1   2002-12-18            Universal acclaim        83.0       ...         \n",
       "2   2005-03-11  Generally favorable reviews        80.0       ...         \n",
       "3   2003-12-24  Generally favorable reviews        67.0       ...         \n",
       "4   2015-11-12                 No score yet         NaN       ...         \n",
       "\n",
       "  Romance SciFi  Short  Sport  TalkShow  Thriller  War  Western  unknown  \\\n",
       "0       0     0      0      0         0         0    0        0        0   \n",
       "1       0     0      0      0         0         0    1        0        0   \n",
       "2       1     0      0      0         0         0    0        0        0   \n",
       "3       1     0      0      0         0         0    0        0        0   \n",
       "4       0     0      0      0         0         0    1        0        0   \n",
       "\n",
       "   release_decade  \n",
       "0           2010s  \n",
       "1           2000s  \n",
       "2           2000s  \n",
       "3           2000s  \n",
       "4           2010s  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "movie_reviews = pd.read_csv('../movie_data.csv')\n",
    "display(movie_reviews.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 0 - Funções de Tratamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_parser(x):\n",
    "    if x not in STOPWORDS:\n",
    "        return ({STEMMER.stem(REGEX.sub('',x).lower()):True})\n",
    "\n",
    "\n",
    "def create_word_features(text):\n",
    "    words={}\n",
    "    for word in word_tokenize(text):\n",
    "        if (word not in STOPWORDS):\n",
    "            words.update(word_parser(word))\n",
    "    return words\n",
    "    \n",
    "def category_filter(category):\n",
    "    reviews = []\n",
    "    for x in movie_reviews.review_text[(movie_reviews.sentiment == category)]:   \n",
    "        reviews.append((create_word_features(x),category))\n",
    "    for x in reviews:\n",
    "        if '' in x[0]:\n",
    "            del x[0]['']\n",
    "    return reviews\n",
    "\n",
    "def predict(model,text):\n",
    "    words = {}\n",
    "    for x in word_tokenize(text):\n",
    "        parsed_word = word_parser(LEMMATIZER.lemmatize(x))\n",
    "        if parsed_word:\n",
    "            words.update(parsed_word)\n",
    "    return model.classify(words)\n",
    "\n",
    "def mode(lista):\n",
    "    counts = [lista.count(x) for x in lista]\n",
    "    return lista[counts.index(max(counts))]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 1 - Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive reviews: 5621\n",
      "Mixed reviews: 5147\n",
      "Negative reviews: 1642\n"
     ]
    }
   ],
   "source": [
    "pos = category_filter('pos')\n",
    "neg = category_filter('neg')\n",
    "mixed = category_filter('mixed')\n",
    "\n",
    "all_classes = pos+neg+mixed\n",
    "shuffle(all_classes)\n",
    "\n",
    "print('Positive reviews:',len(pos)) \n",
    "print('Mixed reviews:',len(mixed))\n",
    "print('Negative reviews:',len(neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 8680 reviews\n",
      "Test set: 3730 reviews\n"
     ]
    }
   ],
   "source": [
    "train_set = all_classes[:8680]\n",
    "test_set = all_classes[8680:]\n",
    "\n",
    "print('Train set: {} reviews'.format(len(train_set)))\n",
    "print('Test set: {} reviews'.format(len(test_set)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 2 - Classificadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NB_classifier = NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MNB_classifier = SklearnClassifier(MultinomialNB()).train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes Classifier (quebrado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#GNB_classifier = SklearnClassifier(GaussianNB()).train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LR_classifier = SklearnClassifier(LogisticRegression()).train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SGD_classifier = SklearnClassifier(SGDClassifier()).train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### SVC Classifier (quebrado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SVC_classifier = SklearnClassifier(SVC()).train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Linear SVC Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LinearSVC_classifier = SklearnClassifier(LinearSVC()).train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### NuSVC Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NuSVC_classifier = SklearnClassifier(NuSVC(nu=0.4)).train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificador por votos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CustomClassifier(ClassifierI):\n",
    "    \n",
    "    def __init__(self,*classifiers):\n",
    "        self._classifiers = classifiers\n",
    "    \n",
    "    def classify(self, feature_set):\n",
    "        return mode([classifier.classify(feature_set) for classifier in self._classifiers]) \n",
    "    \n",
    "    def prob(self, feature_set):\n",
    "        votes = [classifier.classify(feature_set) for classifier in self._classifiers]\n",
    "        return votes.count(mode(votes)) / len(votes)\n",
    "\n",
    "C_classifier = CustomClassifier(NB_classifier, \n",
    "                                     MNB_classifier,\n",
    "                                     LR_classifier,\n",
    "                                     SGD_classifier, \n",
    "                                     LinearSVC_classifier,\n",
    "                                     NuSVC_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 3 - Acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NB Accuracy: 57.56%\n",
      "\n",
      "MNB Accuracy: 60.13%\n",
      "\n",
      "LR Accuracy: 59.12%\n",
      "\n",
      "SGD Accuracy: 56.35%\n",
      "\n",
      "Linear SVC Accuracy: 54.96%\n",
      "\n",
      "NuSVC Accuracy: 56.73%\n",
      "\n",
      "C_Classifier Accuracy: 59.01%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNB Accuracy: %.2f\" %(nltk.classify.util.accuracy(NB_classifier, test_set)*100) + \"%\")\n",
    "\n",
    "print(\"\\nMNB Accuracy: %.2f\" %(nltk.classify.util.accuracy(MNB_classifier, test_set)*100) + \"%\")\n",
    "\n",
    "#print(\"\\nGNB Accuracy: %.2f\" %(nltk.classify.util.accuracy(GNB_classifier, test_set)*100) + \"%\")\n",
    "\n",
    "print(\"\\nLR Accuracy: %.2f\" %(nltk.classify.util.accuracy(LR_classifier, test_set)*100) + \"%\")\n",
    "\n",
    "print(\"\\nSGD Accuracy: %.2f\" %(nltk.classify.util.accuracy(SGD_classifier, test_set)*100) + \"%\")\n",
    "\n",
    "#print(\"\\nSVC Accuracy: %.2f\" %(nltk.classify.util.accuracy(SVC_classifier, test_set)*100) + \"%\")\n",
    "\n",
    "print(\"\\nLinear SVC Accuracy: %.2f\" %(nltk.classify.util.accuracy(LinearSVC_classifier, test_set)*100) + \"%\")\n",
    "\n",
    "print(\"\\nNuSVC Accuracy: %.2f\" %(nltk.classify.util.accuracy(NuSVC_classifier, test_set)*100) + \"%\")\n",
    "\n",
    "print(\"\\nC_Classifier Accuracy: %.2f\" %(nltk.classify.util.accuracy(C_classifier,test_set)*100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 4 - Predições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "Predições para: What a terrible movie, I was bored the whole time!\n",
      "------------------------------------------------------------------\n",
      "\n",
      "NB Classifier: neg\n",
      "\n",
      "MNB Classifier: mixed\n",
      "\n",
      "LRClassifier: neg\n",
      "\n",
      "SGD Classifier: neg\n",
      "\n",
      "Linear SVC Classifier: neg\n",
      "\n",
      "NuSVC Classifier: neg\n",
      "\n",
      "Custom Classifier: neg\n"
     ]
    }
   ],
   "source": [
    "print('------------------------------------------------------------------\\\n",
    "\\nPredições para: What a terrible movie, I was bored the whole time!\\n\\\n",
    "------------------------------------------------------------------\\n')\n",
    "\n",
    "print(\"NB Classifier: {}\\n\".format(predict(NB_classifier, \"What a terrible movie, I was bored the whole time!\")))\n",
    "print(\"MNB Classifier: {}\\n\".format(predict(MNB_classifier, \"What a terrible movie, I was bored the whole time!\")))\n",
    "print(\"LRClassifier: {}\\n\".format(predict(LR_classifier, \"What a terrible movie, I was bored the whole time!\")))\n",
    "print(\"SGD Classifier: {}\\n\".format(predict(SGD_classifier, \"What a terrible movie, I was bored the whole time!\")))\n",
    "#print(\"SVC Classifier: {}\\n\".format(predict(SVC_classifier, \"What a terrible movie, I was bored the whole time!\")))\n",
    "print(\"Linear SVC Classifier: {}\\n\".format(predict(LinearSVC_classifier, \"What a terrible movie, I was bored the whole time!\")))\n",
    "print(\"NuSVC Classifier: {}\\n\".format(predict(NuSVC_classifier, \"What a terrible movie, I was bored the whole time!\")))\n",
    "print(\"Custom Classifier: {}\".format(predict(C_classifier, \"What a terrible movie, I was bored the whole time!\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "Predições para: I love this movie!\n",
      "----------------------------------\n",
      "\n",
      "NB Classifier: pos\n",
      "\n",
      "MNB Classifier: pos\n",
      "\n",
      "LRClassifier: pos\n",
      "\n",
      "SGD Classifier: pos\n",
      "\n",
      "Linear SVC Classifier: pos\n",
      "\n",
      "NuSVC Classifier: pos\n",
      "\n",
      "Custom Classifier: pos\n"
     ]
    }
   ],
   "source": [
    "print('----------------------------------\\\n",
    "\\nPredições para: I love this movie!\\n\\\n",
    "----------------------------------\\n')\n",
    "\n",
    "print(\"NB Classifier: {}\\n\".format(predict(NB_classifier, \"I love this movie!\")))\n",
    "print(\"MNB Classifier: {}\\n\".format(predict(MNB_classifier, \"I love this movie!\")))\n",
    "print(\"LRClassifier: {}\\n\".format(predict(LR_classifier, \"I love this movie!\")))\n",
    "print(\"SGD Classifier: {}\\n\".format(predict(SGD_classifier, \"I love this movie!\")))\n",
    "#print(\"SVC Classifier: {}\\n\".format(predict(SVC_classifier, \"I love this movie!\")))\n",
    "print(\"Linear SVC Classifier: {}\\n\".format(predict(LinearSVC_classifier, \"I love this movie!\")))\n",
    "print(\"NuSVC Classifier: {}\\n\".format(predict(NuSVC_classifier, \"I love this movie!\")))\n",
    "print(\"Custom Classifier: {}\".format(predict(C_classifier, \"I love this movie!\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------\n",
      "Predições para: Even though I think it's average, my wife loves it!\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "NB Classifier: mixed\n",
      "\n",
      "MNB Classifier: mixed\n",
      "\n",
      "LRClassifier: pos\n",
      "\n",
      "SGD Classifier: pos\n",
      "\n",
      "Linear SVC Classifier: neg\n",
      "\n",
      "NuSVC Classifier: pos\n",
      "\n",
      "Custom Classifier: pos\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------------------------------------------------------------\\\n",
    "\\nPredições para: Even though I think it's average, my wife loves it!\\n\\\n",
    "-------------------------------------------------------------------\\n\")\n",
    "\n",
    "print(\"NB Classifier: {}\\n\".format(predict(NB_classifier, \"Even though I think it's average, my wife loves it!\")))\n",
    "print(\"MNB Classifier: {}\\n\".format(predict(MNB_classifier, \"Even though I think it's average, my wife loves it!\")))\n",
    "print(\"LRClassifier: {}\\n\".format(predict(LR_classifier, \"Even though I think it's average, my wife loves it!\")))\n",
    "print(\"SGD Classifier: {}\\n\".format(predict(SGD_classifier, \"Even though I think it's average, my wife loves it!\")))\n",
    "#print(\"SVC Classifier: {}\\n\".format(predict(SVC_classifier, \"Even though I think it's average, my wife loves it!\")))\n",
    "print(\"Linear SVC Classifier: {}\\n\".format(predict(LinearSVC_classifier, \"Even though I think it's average, my wife loves it!\")))\n",
    "print(\"NuSVC Classifier: {}\\n\".format(predict(NuSVC_classifier, \"Even though I think it's average, my wife loves it!\")))\n",
    "print(\"Custom Classifier: {}\".format(predict(C_classifier, \"Even though I think it's average, my wife loves it!\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 5 - Outras Caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                 tedious = True              neg : pos    =     34.4 : 1.0\n",
      "                 incoher = True              neg : pos    =     20.6 : 1.0\n",
      "                   lurch = True              neg : pos    =     20.2 : 1.0\n",
      "                    flat = True              neg : pos    =     19.2 : 1.0\n",
      "                  devast = True              pos : mixed  =     18.9 : 1.0\n",
      "                daughter = True              neg : pos    =     17.8 : 1.0\n",
      "                    poor = True              neg : pos    =     16.8 : 1.0\n",
      "                portrait = True              pos : neg    =     15.6 : 1.0\n",
      "                    sour = True              neg : pos    =     15.4 : 1.0\n",
      "                laughabl = True              neg : pos    =     15.4 : 1.0\n",
      "                    thud = True              neg : pos    =     15.4 : 1.0\n",
      "                  recycl = True              neg : pos    =     15.4 : 1.0\n",
      "                  dreari = True              neg : pos    =     14.9 : 1.0\n",
      "                  suppos = True              neg : pos    =     14.9 : 1.0\n",
      "                 witless = True              neg : mixed  =     13.8 : 1.0\n",
      "                  wouldb = True              neg : pos    =     13.0 : 1.0\n",
      "                  stupid = True              neg : pos    =     13.0 : 1.0\n",
      "                     dud = True              neg : mixed  =     11.7 : 1.0\n",
      "                    lazi = True              neg : pos    =     11.7 : 1.0\n",
      "                inoffens = True            mixed : pos    =     11.5 : 1.0\n"
     ]
    }
   ],
   "source": [
    "NB_classifier.show_most_informative_features(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
