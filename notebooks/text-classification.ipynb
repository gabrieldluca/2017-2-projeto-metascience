{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "from random import shuffle\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from nltk.classify import ClassifierI\n",
    "\n",
    "#nltk.download('stopwords')\n",
    "random.seed(10)\n",
    "\n",
    "STOPWORDS = set(nltk.corpus.stopwords.words('english'))\n",
    "REGEX = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "STEMMER = SnowballStemmer('english')\n",
    "LEMMATIZER = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification (Naive Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>metascore</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_date</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>release_date</th>\n",
       "      <th>user_acclaim</th>\n",
       "      <th>user_score</th>\n",
       "      <th>...</th>\n",
       "      <th>Romance</th>\n",
       "      <th>SciFi</th>\n",
       "      <th>Short</th>\n",
       "      <th>Sport</th>\n",
       "      <th>TalkShow</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "      <th>unknown</th>\n",
       "      <th>release_decade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Notes on Blindness</td>\n",
       "      <td>Stephen Holden</td>\n",
       "      <td>75.0</td>\n",
       "      <td>90</td>\n",
       "      <td>The tone of the narration is so wrenchingly ho...</td>\n",
       "      <td>2016-11-15</td>\n",
       "      <td>pos</td>\n",
       "      <td>2016-11-16</td>\n",
       "      <td>No score yet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Devils on the Doorstep</td>\n",
       "      <td>Stephen Holden</td>\n",
       "      <td>70.0</td>\n",
       "      <td>80</td>\n",
       "      <td>In its dry and forceful way, it delivers the s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pos</td>\n",
       "      <td>2002-12-18</td>\n",
       "      <td>Universal acclaim</td>\n",
       "      <td>83.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Upside of Anger</td>\n",
       "      <td>Dana Stevens</td>\n",
       "      <td>63.0</td>\n",
       "      <td>60</td>\n",
       "      <td>A seriously flawed movie wrapped around two ne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mixed</td>\n",
       "      <td>2005-03-11</td>\n",
       "      <td>Generally favorable reviews</td>\n",
       "      <td>80.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Monster</td>\n",
       "      <td>Stephen Holden</td>\n",
       "      <td>74.0</td>\n",
       "      <td>70</td>\n",
       "      <td>The movie's biggest disappointment is the vagu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pos</td>\n",
       "      <td>2003-12-24</td>\n",
       "      <td>Generally favorable reviews</td>\n",
       "      <td>67.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rock in the Red Zone</td>\n",
       "      <td>Ken Jaworowski</td>\n",
       "      <td>54.0</td>\n",
       "      <td>50</td>\n",
       "      <td>Rock in the Red Zone has its best moments when...</td>\n",
       "      <td>2015-11-12</td>\n",
       "      <td>mixed</td>\n",
       "      <td>2015-11-12</td>\n",
       "      <td>No score yet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    movie        reviewer  metascore  review_score  \\\n",
       "0      Notes on Blindness  Stephen Holden       75.0            90   \n",
       "1  Devils on the Doorstep  Stephen Holden       70.0            80   \n",
       "2     The Upside of Anger    Dana Stevens       63.0            60   \n",
       "3                 Monster  Stephen Holden       74.0            70   \n",
       "4    Rock in the Red Zone  Ken Jaworowski       54.0            50   \n",
       "\n",
       "                                         review_text review_date sentiment  \\\n",
       "0  The tone of the narration is so wrenchingly ho...  2016-11-15       pos   \n",
       "1  In its dry and forceful way, it delivers the s...         NaN       pos   \n",
       "2  A seriously flawed movie wrapped around two ne...         NaN     mixed   \n",
       "3  The movie's biggest disappointment is the vagu...         NaN       pos   \n",
       "4  Rock in the Red Zone has its best moments when...  2015-11-12     mixed   \n",
       "\n",
       "  release_date                 user_acclaim  user_score       ...        \\\n",
       "0   2016-11-16                 No score yet         NaN       ...         \n",
       "1   2002-12-18            Universal acclaim        83.0       ...         \n",
       "2   2005-03-11  Generally favorable reviews        80.0       ...         \n",
       "3   2003-12-24  Generally favorable reviews        67.0       ...         \n",
       "4   2015-11-12                 No score yet         NaN       ...         \n",
       "\n",
       "  Romance SciFi  Short  Sport  TalkShow  Thriller  War  Western  unknown  \\\n",
       "0       0     0      0      0         0         0    0        0        0   \n",
       "1       0     0      0      0         0         0    1        0        0   \n",
       "2       1     0      0      0         0         0    0        0        0   \n",
       "3       1     0      0      0         0         0    0        0        0   \n",
       "4       0     0      0      0         0         0    1        0        0   \n",
       "\n",
       "   release_decade  \n",
       "0           2010s  \n",
       "1           2000s  \n",
       "2           2000s  \n",
       "3           2000s  \n",
       "4           2010s  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "movie_reviews = pd.read_csv('../movie_data.csv')\n",
    "display(movie_reviews.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 0 - Funções"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para otimizar os resultados obtidos com os classificadores, é necessário fazer o tratamento dos textos das resenhas existentes no base de dados. Foram usadas tecnicas como remoção de stopwords, stemmização, tokenização por palavra (nltk word_tokenizer) e lemmatização. Para facilitar a leitura e entendimento do notebook, as funções de tratamento e categorização foram agrupadas em uma só celula, bem como as funções necessárias futuramente em classificadores especificos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_parser(x):\n",
    "    if x not in STOPWORDS:\n",
    "        return ({STEMMER.stem(REGEX.sub('',x).lower()):True})\n",
    "\n",
    "\n",
    "def create_word_features(text):\n",
    "    words={}\n",
    "    for word in word_tokenize(text):\n",
    "        if (word not in STOPWORDS):\n",
    "            words.update(word_parser(word))\n",
    "    return words\n",
    "    \n",
    "def category_filter(category):\n",
    "    reviews = []\n",
    "    for x in movie_reviews.review_text[(movie_reviews.sentiment == category)]:   \n",
    "        reviews.append((create_word_features(x),category))\n",
    "    for x in reviews:\n",
    "        if '' in x[0]:\n",
    "            del x[0]['']\n",
    "    return reviews\n",
    "\n",
    "def predict(model,text):\n",
    "    words = {}\n",
    "    for x in word_tokenize(text):\n",
    "        parsed_word = word_parser(LEMMATIZER.lemmatize(x))\n",
    "        if parsed_word:\n",
    "            words.update(parsed_word)\n",
    "    return model.classify(words)\n",
    "\n",
    "def mode(lista):\n",
    "    counts = [lista.count(x) for x in lista]\n",
    "    return lista[counts.index(max(counts))]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 1 - Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após aplicar as tecnicas de tratamento às palavras utilizando as funções acima, é necessário categorizar e criar features para cada classe de palavra. Os classificadores serão treinados com 3 classes: 'pos', 'neg' e 'mixed', que representam, respectivamente, os sentimentos 'positivo', 'negativo' e 'neutro'. Aplicaremos então uma função de aleatorização à lista de todas as palavras do banco de dados já categorizadas para prosseguir com a criação do conjunto de treinamento (70% do total de reviews) e de teste (30% do total de reviews)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive reviews: 5621\n",
      "Mixed reviews: 5147\n",
      "Negative reviews: 1642\n"
     ]
    }
   ],
   "source": [
    "pos = category_filter('pos')\n",
    "neg = category_filter('neg')\n",
    "mixed = category_filter('mixed')\n",
    "\n",
    "all_classes = pos+neg+mixed\n",
    "shuffle(all_classes)\n",
    "\n",
    "print('Positive reviews:',len(pos)) \n",
    "print('Mixed reviews:',len(mixed))\n",
    "print('Negative reviews:',len(neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 8680 reviews\n",
      "Test set: 3730 reviews\n"
     ]
    }
   ],
   "source": [
    "train_set = all_classes[:8680]\n",
    "test_set = all_classes[8680:]\n",
    "\n",
    "print('Train set: {} reviews'.format(len(train_set)))\n",
    "print('Test set: {} reviews'.format(len(test_set)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 2 - Classificadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta etapa, usando nltk e sua integração com sklearn, treinaremos diversos classificadores com o conjunto de treinamento definido prosteriormente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NB_classifier = NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MNB_classifier = SklearnClassifier(MultinomialNB()).train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LR_classifier = SklearnClassifier(LogisticRegression()).train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SGD_classifier = SklearnClassifier(SGDClassifier()).train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### SVC Classifier (quebrado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVC_classifier = SklearnClassifier(SVC()).train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Linear SVC Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LinearSVC_classifier = SklearnClassifier(LinearSVC()).train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### NuSVC Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "NuSVC_classifier = SklearnClassifier(NuSVC(nu=0.3)).train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificador por votos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que treinamos diversos classificadores disponíveis no sklearn e nltk, criaremos nosso próprio classficador. Ele funcionará como uma espécie de conselho, onde coletará o resultado de 6 outros classificadores e, baseado neles, retornará o resultado com mais ocorrencia entre eles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CustomClassifier(ClassifierI):\n",
    "    \n",
    "    def __init__(self,*classifiers):\n",
    "        self._classifiers = classifiers\n",
    "    \n",
    "    def classify(self, feature_set):\n",
    "        return mode([classifier.classify(feature_set) for classifier in self._classifiers]) \n",
    "    \n",
    "    def prob(self, feature_set):\n",
    "        votes = [classifier.classify(feature_set) for classifier in self._classifiers]\n",
    "        return votes.count(mode(votes)) / len(votes)\n",
    "\n",
    "C_classifier = CustomClassifier(NB_classifier, \n",
    "                                     MNB_classifier,\n",
    "                                     LR_classifier,\n",
    "                                     SGD_classifier,\n",
    "                                     SVC_classifier,\n",
    "                                     LinearSVC_classifier,\n",
    "                                     NuSVC_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#função para uso futuros\n",
    "def trainClassifiers(train_set):\n",
    "    NB_classifier = NaiveBayesClassifier.train(train_set)\n",
    "    LR_classifier = SklearnClassifier(LogisticRegression()).train(train_set)\n",
    "    SGD_classifier = SklearnClassifier(SGDClassifier()).train(train_set)\n",
    "    SVC_classifier = SklearnClassifier(SVC()).train(train_set)\n",
    "    LinearSVC_classifier = SklearnClassifier(LinearSVC()).train(train_set)\n",
    "    NuSVC_classifier = SklearnClassifier(NuSVC(nu=0.3)).train(train_set)\n",
    "    NB_classifier = NaiveBayesClassifier.train(train_set)\n",
    "    C_classifier = CustomClassifier(NB_classifier, \n",
    "                                     MNB_classifier,\n",
    "                                     LR_classifier,\n",
    "                                     SGD_classifier,\n",
    "                                     SVC_classifier,\n",
    "                                     LinearSVC_classifier,\n",
    "                                     NuSVC_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 3 - Acurácia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criados e treinados os classificadores, verificaremos a acurácia de cada um deles usando o nosso conjunto de teste definido na etapa 1 deste notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NB Accuracy: 57.56%\n",
      "\n",
      "MNB Accuracy: 60.13%\n",
      "\n",
      "LR Accuracy: 59.12%\n",
      "\n",
      "SGD Accuracy: 55.98%\n",
      "\n",
      "SVC Accuracy: 43.91%\n",
      "\n",
      "Linear SVC Accuracy: 54.96%\n",
      "\n",
      "NuSVC Accuracy: 55.50%\n",
      "\n",
      "C_Classifier Accuracy: 58.28%\n"
     ]
    }
   ],
   "source": [
    "def testAccuracy(test_set):\n",
    "    print(\"\\nNB Accuracy: %.2f\" %(nltk.classify.util.accuracy(NB_classifier, test_set)*100) + \"%\")\n",
    "    print(\"\\nMNB Accuracy: %.2f\" %(nltk.classify.util.accuracy(MNB_classifier, test_set)*100) + \"%\")\n",
    "    print(\"\\nLR Accuracy: %.2f\" %(nltk.classify.util.accuracy(LR_classifier, test_set)*100) + \"%\")\n",
    "    print(\"\\nSGD Accuracy: %.2f\" %(nltk.classify.util.accuracy(SGD_classifier, test_set)*100) + \"%\")\n",
    "    print(\"\\nSVC Accuracy: %.2f\" %(nltk.classify.util.accuracy(SVC_classifier, test_set)*100) + \"%\")\n",
    "    print(\"\\nLinear SVC Accuracy: %.2f\" %(nltk.classify.util.accuracy(LinearSVC_classifier, test_set)*100) + \"%\")\n",
    "    print(\"\\nNuSVC Accuracy: %.2f\" %(nltk.classify.util.accuracy(NuSVC_classifier, test_set)*100) + \"%\")\n",
    "    print(\"\\nC_Classifier Accuracy: %.2f\" %(nltk.classify.util.accuracy(C_classifier,test_set)*100) + \"%\")\n",
    "\n",
    "testAccuracy(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos, após diversos testes com esses classificadores, que o Multinomial Naive Bayes e o nosso classificador por votos se destacam ao mostrar, em quase todos, as maiores acurácias para a nossa base de dados. No entanto, o SVC apresentou uma acurácia muito abaixo da média."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 4 - Investigando bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para investigar se existe alguma polarização no julgamento dos classificadores, nesta etapa testaremos a acurácia de cada um deles para apenas reviews negativos e para apenas reviews positivos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive reviews: 5621\n",
      "Mixed reviews: 5147\n",
      "Negative reviews: 1642\n",
      "\n",
      "Train set: 11768 reviews\n",
      "Test set: 642 reviews\n",
      "\n",
      "NB Accuracy: 72.12%\n",
      "\n",
      "MNB Accuracy: 37.38%\n",
      "\n",
      "LR Accuracy: 64.17%\n",
      "\n",
      "SGD Accuracy: 64.49%\n",
      "\n",
      "SVC Accuracy: 0.00%\n",
      "\n",
      "Linear SVC Accuracy: 73.68%\n",
      "\n",
      "NuSVC Accuracy: 65.11%\n",
      "\n",
      "C_Classifier Accuracy: 65.42%\n"
     ]
    }
   ],
   "source": [
    "#Negative\n",
    "\n",
    "pos = category_filter('pos')\n",
    "neg = category_filter('neg')\n",
    "mixed = category_filter('mixed')\n",
    "\n",
    "all_classes = pos+neg[:1000]+mixed\n",
    "shuffle(all_classes)\n",
    "\n",
    "print('Positive reviews: {}'.format(len(pos))) \n",
    "print('Mixed reviews: {}'.format(len(mixed)))\n",
    "print('Negative reviews: {}\\n'.format(len(neg)))\n",
    "\n",
    "train_set = all_classes\n",
    "test_set = neg[1000:]\n",
    "\n",
    "print('Train set: {} reviews'.format(len(train_set)))\n",
    "print('Test set: {} reviews'.format(len(test_set)))\n",
    "\n",
    "trainClassifiers(train_set)\n",
    "testAccuracy(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos, após a primeira investigação, uma acurácia de 0% no classificador SVC, resultado extremamente improvável e que indica bias. Além disso, ao testarmos várias vezes, temos um resultado bastante heterogêneo dos outros classificadores, que pode ser causado pela baixa quantidade de amostras negativas no conjunto de treinamento, que tem apenas 1000 reviews negativos em comparação com os mais de 10000 reviews positivos e mixed. Para confirmar o bias do classificador SVC, testaremos os modelos com um conjunto de teste unicamente positivo.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive reviews: 5621\n",
      "Mixed reviews: 5147\n",
      "Negative reviews: 1642\n",
      "\n",
      "Train set: 11410 reviews\n",
      "Test set: 1000 reviews\n",
      "\n",
      "NB Accuracy: 84.50%\n",
      "\n",
      "MNB Accuracy: 87.50%\n",
      "\n",
      "LR Accuracy: 90.10%\n",
      "\n",
      "SGD Accuracy: 87.50%\n",
      "\n",
      "SVC Accuracy: 100.00%\n",
      "\n",
      "Linear SVC Accuracy: 90.40%\n",
      "\n",
      "NuSVC Accuracy: 83.90%\n",
      "\n",
      "C_Classifier Accuracy: 92.20%\n"
     ]
    }
   ],
   "source": [
    "#Positive\n",
    "\n",
    "pos = category_filter('pos')\n",
    "neg = category_filter('neg')\n",
    "mixed = category_filter('mixed')\n",
    "\n",
    "all_classes = pos[1000:]+neg+mixed\n",
    "shuffle(all_classes)\n",
    "\n",
    "print('Positive reviews: {}'.format(len(pos))) \n",
    "print('Mixed reviews: {}'.format(len(mixed)))\n",
    "print('Negative reviews: {}\\n'.format(len(neg)))\n",
    "\n",
    "train_set = all_classes\n",
    "test_set = pos[:1000]\n",
    "\n",
    "print('Train set: {} reviews'.format(len(train_set)))\n",
    "print('Test set: {} reviews'.format(len(test_set)))\n",
    "\n",
    "trainClassifiers(train_set)\n",
    "testAccuracy(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos, após testar os modelos com amostras positivas, o SVC apresenta uma acurácia de 100%, o que confirma a hipótese de que ele estava polarizado. Vemos também que os outros classificadores tiveram maior facilidade em detectar reviews positivos em comparação com os negativos. Essa diferença pode ser causada por um conjunto de dados desequilibrado. Seguimos, então, com o teste para a categoria 'mixed'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive reviews: 5621\n",
      "Mixed reviews: 5147\n",
      "Negative reviews: 1642\n",
      "\n",
      "Train set: 11410 reviews\n",
      "Test set: 1000 reviews\n",
      "\n",
      "NB Accuracy: 73.40%\n",
      "\n",
      "MNB Accuracy: 79.90%\n",
      "\n",
      "LR Accuracy: 83.10%\n",
      "\n",
      "SGD Accuracy: 78.30%\n",
      "\n",
      "SVC Accuracy: 0.00%\n",
      "\n",
      "Linear SVC Accuracy: 83.60%\n",
      "\n",
      "NuSVC Accuracy: 74.80%\n",
      "\n",
      "C_Classifier Accuracy: 79.60%\n"
     ]
    }
   ],
   "source": [
    "#Mixed\n",
    "\n",
    "pos = category_filter('pos')\n",
    "neg = category_filter('neg')\n",
    "mixed = category_filter('mixed')\n",
    "\n",
    "all_classes = pos+neg+mixed[1000:]\n",
    "shuffle(all_classes)\n",
    "\n",
    "print('Positive reviews: {}'.format(len(pos))) \n",
    "print('Mixed reviews: {}'.format(len(mixed)))\n",
    "print('Negative reviews: {}\\n'.format(len(neg)))\n",
    "\n",
    "train_set = all_classes\n",
    "test_set = mixed[:1000]\n",
    "\n",
    "print('Train set: {} reviews'.format(len(train_set)))\n",
    "print('Test set: {} reviews'.format(len(test_set)))\n",
    "\n",
    "trainClassifiers(train_set)\n",
    "testAccuracy(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os resultados se aproximam bastante dos resultados do teste para reviews positivos, o que é esperado considerando a quantidade parecida de reviews para as duas classes. O SVC, assim como no teste com reviews negativos, também mostra uma acurácia de 0%, reforçando a confirmação de que o classificador está classificando qualquer review como positivo e por isso será descartado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 4 - Predições"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para finalizar, faremos algumas predições e veremos o resultado de cada classificador para cada uma delas. É possível ver também que o classificador baseado em votos feito por nós está, de fato, retornando a resposta mais comum entre os outros classificadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predições para: What a terrible movie, I was bored the whole time!\n",
      "-----------\n",
      "NB Classifier: neg\n",
      "\n",
      "MNB Classifier: mixed\n",
      "\n",
      "LRClassifier: neg\n",
      "\n",
      "SGD Classifier: neg\n",
      "\n",
      "Linear SVC Classifier: neg\n",
      "\n",
      "NuSVC Classifier: neg\n",
      "\n",
      "Custom Classifier: neg\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def classifiers_predict(review):\n",
    "    print('\\nPredições para: {}\\n-----------'.format(review))\n",
    "\n",
    "    print(\"NB Classifier: {}\\n\".format(predict(NB_classifier, review)))\n",
    "    print(\"MNB Classifier: {}\\n\".format(predict(MNB_classifier, review)))\n",
    "    print(\"LRClassifier: {}\\n\".format(predict(LR_classifier, review)))\n",
    "    print(\"SGD Classifier: {}\\n\".format(predict(SGD_classifier, review)))\n",
    "    print(\"Linear SVC Classifier: {}\\n\".format(predict(LinearSVC_classifier, review)))\n",
    "    print(\"NuSVC Classifier: {}\\n\".format(predict(NuSVC_classifier, review)))\n",
    "    print(\"Custom Classifier: {}\\n\".format(predict(C_classifier, review)))\n",
    "    \n",
    "classifiers_predict(\"What a terrible movie, I was bored the whole time!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predições para: I love this movie!\n",
      "-----------\n",
      "NB Classifier: pos\n",
      "\n",
      "MNB Classifier: pos\n",
      "\n",
      "LRClassifier: pos\n",
      "\n",
      "SGD Classifier: pos\n",
      "\n",
      "Linear SVC Classifier: pos\n",
      "\n",
      "NuSVC Classifier: pos\n",
      "\n",
      "Custom Classifier: pos\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers_predict(\"I love this movie!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predições para: Even though I think it's average, my wife loves it!\n",
      "-----------\n",
      "NB Classifier: mixed\n",
      "\n",
      "MNB Classifier: mixed\n",
      "\n",
      "LRClassifier: pos\n",
      "\n",
      "SGD Classifier: pos\n",
      "\n",
      "Linear SVC Classifier: neg\n",
      "\n",
      "NuSVC Classifier: pos\n",
      "\n",
      "Custom Classifier: pos\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers_predict(\"Even though I think it's average, my wife loves it!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 5 - Outras Caracteristicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função \"show_most_informative_features\", do classificador Naive Bayes, é interessante pois mostra as palavras que são mais significativas para o modelo. Isto é, quando detectadas, aumentam consideravelmente a probabilidade do classificador acertar a classe do review testado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                 tedious = True              neg : pos    =     34.4 : 1.0\n",
      "                 incoher = True              neg : pos    =     20.6 : 1.0\n",
      "                   lurch = True              neg : pos    =     20.2 : 1.0\n",
      "                    flat = True              neg : pos    =     19.2 : 1.0\n",
      "                  devast = True              pos : mixed  =     18.9 : 1.0\n",
      "                daughter = True              neg : pos    =     17.8 : 1.0\n",
      "                    poor = True              neg : pos    =     16.8 : 1.0\n",
      "                portrait = True              pos : neg    =     15.6 : 1.0\n",
      "                    sour = True              neg : pos    =     15.4 : 1.0\n",
      "                  recycl = True              neg : pos    =     15.4 : 1.0\n",
      "                    thud = True              neg : pos    =     15.4 : 1.0\n",
      "                laughabl = True              neg : pos    =     15.4 : 1.0\n",
      "                  dreari = True              neg : pos    =     14.9 : 1.0\n",
      "                  suppos = True              neg : pos    =     14.9 : 1.0\n",
      "                 witless = True              neg : mixed  =     13.8 : 1.0\n",
      "                  stupid = True              neg : pos    =     13.0 : 1.0\n",
      "                  wouldb = True              neg : pos    =     13.0 : 1.0\n",
      "                     dud = True              neg : mixed  =     11.7 : 1.0\n",
      "                    lazi = True              neg : pos    =     11.7 : 1.0\n",
      "                inoffens = True            mixed : pos    =     11.5 : 1.0\n"
     ]
    }
   ],
   "source": [
    "NB_classifier.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao pedir ao classificador as 20 palavras mais informativas, é possível observar que reviews negativos carregam um conjunto de palavras mais especificas e comuns entre eles, apesar da pequena quantidade de amostras dessa classe no conjunto de dados. Tedious e Incoherent (incoher após a stemmização) aparecem, por exemplo, 34.4 e 20.6 vezes mais frequentemente em reviews negativos se comparados com positivos. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
